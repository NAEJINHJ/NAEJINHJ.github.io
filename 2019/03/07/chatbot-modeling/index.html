<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">

    

    
    <title>딥러닝 모델을 통한 챗봇 만들기 : 모델링 | NA&#39;rchive</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="python,BIGDATA,NLP,Chatbot">
    
    <meta name="description" content="[목차]          모델 개요            &amp;lt;모델링&amp;gt;      configs      data      model      main      predict            정리 및 참고          [모델 개요]        챗봇을 만들기 위해 사용할 모델은 시퀀스 두 시퀀스(Sequence to Sequence">
<meta name="keywords" content="python,BIGDATA,NLP,Chatbot">
<meta property="og:type" content="article">
<meta property="og:title" content="딥러닝 모델을 통한 챗봇 만들기 : 모델링">
<meta property="og:url" content="https://NAEJINHJ.github.com/2019/03/07/chatbot-modeling/index.html">
<meta property="og:site_name" content="NA&#39;rchive">
<meta property="og:description" content="[목차]          모델 개요            &amp;lt;모델링&amp;gt;      configs      data      model      main      predict            정리 및 참고          [모델 개요]        챗봇을 만들기 위해 사용할 모델은 시퀀스 두 시퀀스(Sequence to Sequence">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://naejinhj.github.com/image/NLP/chatbot/chatbot.PNG">
<meta property="og:updated_time" content="2019-03-07T02:58:49.985Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="딥러닝 모델을 통한 챗봇 만들기 : 모델링">
<meta name="twitter:description" content="[목차]          모델 개요            &amp;lt;모델링&amp;gt;      configs      data      model      main      predict            정리 및 참고          [모델 개요]        챗봇을 만들기 위해 사용할 모델은 시퀀스 두 시퀀스(Sequence to Sequence">
<meta name="twitter:image" content="https://naejinhj.github.com/image/NLP/chatbot/chatbot.PNG">
    

    

    
        <link rel="icon" href="/css/images/favicon.ico">
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    


</head>
</html>
<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                  <h1 class="logo-wrap">
                     <a href="/" class="logo"></a>
                 </h1>
                 
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/BIGDATA/">BIGDATA</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/BIGDATA/DATA/">DATA</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/BIGDATA/Modeling/">Modeling</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/BIGDATA/NLP/">NLP</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Coding-Test/">Coding Test</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Coding-Test/Python/">Python</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/DB/">DB</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/DB/NoSQL/">NoSQL</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/LOG/">LOG</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/">Project</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/BIGDATA/">BIGDATA</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/C/">C#</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/JAVA/">JAVA</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/Kaggle/">Kaggle</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Project/NLP/">NLP</a></li></ul></li></ul>
                                    
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/BIGDATA/">BIGDATA</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/BIGDATA/NLP/">NLP</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-chatbot-modeling" class="article article-single article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        딥러닝 모델을 통한 챗봇 만들기 : 모델링
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2019/03/07/chatbot-modeling/" class="article-date">
            <time datetime="2019-03-07T02:58:59.337Z" itemprop="datePublished">2019-03-07</time>
        </a>
    </div>

		

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/BIGDATA/">BIGDATA</a>, <a class="tag-link" href="/tags/Chatbot/">Chatbot</a>, <a class="tag-link" href="/tags/NLP/">NLP</a>, <a class="tag-link" href="/tags/python/">python</a>
    </div>

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <font size="3"><br>  <img src="/image/NLP/chatbot/chatbot.PNG"><br>  <div style="background-color:rgba(0, 0, 0, 0.0470588); text-align:center; vertical-align: middle; padding:30px 0;"><br>    <font size="4"><b>[목차]</b></font><br>    <font size="4"><br>      <a href="#section1"><font color="hotpink"><b>모델 개요</b></font></a><br>      <hr><br>      <a href="#section2"><font color="hotpink"><b>&lt;모델링&gt;</b></font></a><br>      <a href="#section3">configs</a><br>      <a href="#section4">data</a><br>      <a href="#section5">model</a><br>      <a href="#section6">main</a><br>      <a href="#section7">predict</a><br>      <hr><br>      <a href="#section8"><font color="hotpink"><b>정리 및 참고</b></font></a><br>    </font><br>  </div><br>  <div id="section1"><br>  <font size="5" color="purple"><b>[모델 개요]</b></font><br>  <hr color="purple"><br>  <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>    챗봇을 만들기 위해 사용할 모델은 <b><font color="purple" size="4">시퀀스 두 시퀀스</font></b><font size="2">(Sequence to Sequence)</font>다<br>    이름 그대로 <font color="hotpink"><b>시퀀스 형태의 입력값을 시퀀스 형태의 출력으로</b></font> 만드는 모델이다<br>    즉, <b>하나의 텍스트 문장이 입력</b>으로 들어오면 <b>하나의 텍스트 문장이 출력</b>된다<br>    <br><br>    해당 모델은 <font color="hotpink"><b>RNN</b></font><font size="2">(재귀 순환 신경망)</font>을 기반으로 하며,<br>    크게 <b>Encoder</b> 부분과 <b>Decoder</b> 부분으로 나뉜다<br>    우선 <b><font color="hotpink">인코더</font> 부분에서 입력값을 받아 <font color="hotpink">정보를 담은 벡터</font></b>를 만들어 낸다<br>    이후 <b><font color="hotpink">디코더</font>에서 이 벡터를 활용해 <font color="hotpink">재귀적으로 출력값</font></b>을 만들어내는 구조이다<br>    <img src="/image/NLP/chatbot/sequence_to_sequence.png"><br>    그림 좌측의 <b><font color="purple" size="4">인코더</font></b>에서는<br>    각 재귀 순환 신경망의 <b>스텝마다 입력값</b>이 들어가고 있다<br>    이때 <b>입력값은 하나의 단어</b>가 된다<br>    또한 해당 부분의 전체 RNN 마지막 부분에서<br>    <font color="hotpink"><b>contet vector</b></font>라는 하나의 벡터값이 나온다<br>    <font size="2">(재귀 순환 신경망의 마지막 은닉 상태 벡터값)</font><br>    이는 <b>인코더 부분의 정보를 요약</b>해 담고 있는 벡터이다<br>    <br><br>    <b><font color="purple" size="4">디코더</font></b> 부분으로 들어가면<br>    이 벡터를 사용해 <b>새롭게 RNN을 시작</b>한다<br>    이 신경망의 <b>각 스텝마다 출력값<font size="2">(하나의 단어)</font>이 하나씩</b> 나온다<br>    해당 부분은<b> 각 스텝에서의 출력값이 다시 다음 스텝으로 들어가는 구조</b>로,<br>    <font color="hotpink"><b>각 스텝의 출력값이 다음 스텝의 입력값으로</b></font> 사용된다<br>    <br><br>    <img src="/image/NLP/chatbot/sequence_to_sequence_str.PNG"><br>    <b><font color="purple" size="4">인코더</font></b> 부분을 보면<br>    각 신경망의 각 <b>스텝마다 단어가 하나씩</b> 들어가고 있다<br>    각 단어는 <font color="hotpink"><b>임베딩된 벡터</b></font>로 변환 후, 입력값으로 사용된다<br>    재현 신경망의 경우, 구현 시 <b>고정된 문장 길이</b>를 정해야 한다<br>    고정된 문장 길이보다 입력된 문장의 길이가 짧을 시, <b>PADDING을 수행</b>한다<br>    <br><br>    <b><font color="purple" size="4">디코더</font></b>에서는<br>    최조 입력값으로 <font color="hotpink"><b>START</b></font>라는 특정 토큰<font size="2">(문장의 시작을 나타내는 토큰)</font>을 사용한다<br>    디코더 역시 해당 단어가 <b>임베딩된 벡터 형태</b>로 입력되고,<br>    각 <b>스텝마다 출력</b>이 나온다<br>    이렇게 나온 <b>출력 단어가 다음 스텝의 입력값</b>으로 사용된다<br>    반복 후, 최종적으로 <font color="hotpink"><b>END</b></font>라는 토큰이 나오면<br>    <font color="hotpink"><b>문장의 끝으로 간주</b></font>하는 형태로 학습을 진행한다<br>    <br><br>    <font color="purple" size="4"><b>데이터 전처리 과정</b></font>에서 <b>특정 문장 길이로</b> 자른 후<br>    <b>패딩 처리</b> 및 <b>START나 END 등의 각종 토큰</b>을 넣어야 한다<br>  </div><br>  <div id="section2"><br>  <font size="5" color="purple"><b>[모델링]</b></font><br>  <hr color="purple"><br>  <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>    모델 구현은 여러 개의 파이썬 파일로 구현할 것이다<br>    우선, <font color="hotpink"><b>전체적인 파일 구조</b></font>를 알아보자<br>    <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── data_in                   # 입력되는 데이터가 모여있는 폴더</span><br><span class="line">  ├── ChatBotData.csv           # 전체 데이터</span><br><span class="line">  ├── ChatBotData.csv_short     # 축소된 데이터 (테스트 용도)</span><br><span class="line">  ├── README.md                 # 데이터 저자 READMD 파일</span><br><span class="line"></span><br><span class="line">├── data_out                  # 출력되는 모든 데이터가 모여있는 폴더</span><br><span class="line">  ├── vocabularyData.voc        # 사전 파일</span><br><span class="line">  ├── check<span class="emphasis">_point               # check_</span>point 저장 공간</span><br><span class="line"></span><br><span class="line">├── config.py                 # 모델 설정값 지정 소스</span><br><span class="line">├── data.py                    # data 전처리 및 모델에 주입되는 data set 만드는 소스</span><br><span class="line">├── main.py                    # 전체적으로 데이터를 불러오고, 모델 실행</span><br><span class="line">├── model.py                   # 시퀀스 투 시퀀스 모델이 들어 있는 소스</span><br><span class="line">└── predict.py                 # 학습된 모델로 챗봇 기능 사용하기 위한 코드</span><br></pre></td></tr></table></figure><br>    크게 <b>두 개의 폴더</b>와<br>    <b>5개의 파이썬 파일</b>로 구성되어 있다<br>    <br><br>    <div id="section3"><br>    <font size="4" color="blue"><b>[config]</b></font><br>    <hr color="blue"><br>    config 코드에는 전체적으로 각종 파라미터로 사용 될<br>    <b>하이퍼파라미터 값이 키-값 형태로 지정</b>되어 있다<br>    <br><br>    <font color="hotpink"><b>tf.app.flags</b></font> 기능을 사용하면 하이퍼 파라미터 값을 지정할 수 있으며,<br>    자료형에 따라 <font color="hotpink"><b>DEFINE_</b></font><font size="2">(data type)</font> 형태로 지정해두면 된다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 주피터에서 커널에 전달하기 위한 프래그 방법</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'f'</span>,<span class="string">''</span>,<span class="string">'kernel'</span>)</span><br><span class="line"><span class="comment"># 배치 크기</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'batch_size'</span>,<span class="number">64</span>,<span class="string">'batch size'</span>)</span><br><span class="line"><span class="comment"># 학습 에폭</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'train_steps'</span>,<span class="number">10000</span>,<span class="string">'train steps'</span>)</span><br><span class="line"><span class="comment"># 드롭아웃 크기</span></span><br><span class="line">tf.app.flags.DEFINE_float(<span class="string">'dropout_width'</span>,<span class="number">0.5</span>,<span class="string">'dropout width'</span>)</span><br><span class="line"><span class="comment"># 멀티 레이어 크기 (multi rnn)</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'layer_size'</span>,<span class="number">3</span>,<span class="string">'layer size'</span>)</span><br><span class="line"><span class="comment"># 가중치 크기</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'hidden_size'</span>,<span class="number">128</span>,<span class="string">'weights size'</span>)</span><br><span class="line"><span class="comment"># 학습률</span></span><br><span class="line">tf.app.flags.DEFINE_float(<span class="string">'learning_rate'</span>,<span class="number">1e-3</span>,<span class="string">'learning rate'</span>)</span><br><span class="line"><span class="comment"># 데이터 위치</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'data_path'</span>,<span class="string">'./data_in/ChatBotData.csv'</span>,<span class="string">'data path'</span>)</span><br><span class="line"><span class="comment"># 사전 위치</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'vocabulary_path'</span>,</span><br><span class="line"><span class="string">'./data_out/vocabularyData.voc'</span>,<span class="string">'vocabulary path'</span>)</span><br><span class="line"><span class="comment"># 체크 포인트 위치</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">'check_point_path'</span>,</span><br><span class="line"><span class="string">'./data_out/check_point'</span>,<span class="string">'check point path'</span>)</span><br><span class="line"><span class="comment"># 셔플 시드값</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'shuffle_seek'</span>,<span class="number">1000</span>,</span><br><span class="line"><span class="string">'shuffle random seek'</span>)</span><br><span class="line"><span class="comment"># 시퀀스 길이</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'max_sequence_length'</span>,<span class="number">25</span>,</span><br><span class="line"><span class="string">'max sequence length'</span>)</span><br><span class="line"><span class="comment"># 임베딩 크기</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'embedding_size'</span>,<span class="number">128</span>,<span class="string">'embedding size'</span>)</span><br><span class="line"><span class="comment"># 형태소에 따른 토크나이징 사용 여부</span></span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'tokenize_as_morph'</span>,<span class="keyword">True</span>,</span><br><span class="line"><span class="string">'set morph tokenize'</span>)</span><br><span class="line"><span class="comment"># 임베딩 여부 설정</span></span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'embedding'</span>,<span class="keyword">True</span>,<span class="string">'Use Embedding flag'</span>)</span><br><span class="line"><span class="comment"># 멀티 RNN 여부</span></span><br><span class="line">tf.app.flags.DEFINE_boolean(<span class="string">'multilayer'</span>,<span class="keyword">True</span>,<span class="string">'Use Multi Rnn Cell'</span>)</span><br><span class="line"><span class="comment"># Define FLAGS</span></span><br><span class="line">DEFINES = tf.app.flags.FLAGS</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    이 값들은 각 코드 파일에서<br>    <b>다음과 같이 불러온 후</b> 사용한다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> DEFINES</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    <br><br>    <div id="section4"><br>    <font size="4" color="blue"><b>[data]</b></font><br>    <hr color="blue"><br>    <font color="hotpink"><b>데이터 불러오기, 데이터 전처리</b></font> 등<br>    데이터와 관련된 모든 기능이 구현되어 있다<br>    <br><br>    필요 <b>라이브러리 import</b><br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> enum</span><br><span class="line"><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Okt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> DEFINES</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    먼저, <font color="hotpink"><b>데이터 처리</b></font>와 관련해<br>    몇 가지 <b>설정값을 지정</b>한다<br>    <br><br>    정규 표현식에서 <font color="hotpink"><b>사용할 필터</b></font>와<br>    <font color="hotpink"><b>PADDING, START, END, UNKNOWN 토큰</b></font>과 해당 <font color="hotpink"><b>토큰들의 인덱스 값</b></font>을 지정한다<br>    필터의 경우, 정규 표현식 모듈을 사용해 컴파일 한다<br>    <font size="2">(미리 컴파일 시, 패턴 사용할 때 반복적인 컴파일 시간 감축 가능)</font><br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FILTER = <span class="string">"([~.,!?\"':;)(])"</span></span><br><span class="line">PAD = <span class="string">"&lt;PADDING&gt;"</span></span><br><span class="line">STD = <span class="string">"&lt;START&gt;"</span></span><br><span class="line">END = <span class="string">"&lt;END&gt;"</span></span><br><span class="line">UNK = <span class="string">"&lt;UNKNOWN&gt;"</span></span><br><span class="line"></span><br><span class="line">PAD_INDEX = <span class="number">0</span></span><br><span class="line">STD_INDEX = <span class="number">1</span></span><br><span class="line">END_INDEX = <span class="number">2</span></span><br><span class="line">UNK_INDEX = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">MARKER = [PAD,STD,END,UNK]</span><br><span class="line">CHANGE_FILTER = re.compile(FILTERS)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 데이터를 불러와<br>    <font color="hotpink"><b>학습 데이터</b></font>와 <font color="hotpink"><b>검증 데이터</b></font>로 분리하는 함수이다<br>    <b>67 : 33 비율</b>로 분리하였다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">()</span>:</span></span><br><span class="line">    data_df = pd.read_csv(DEFINES.data_path,header=<span class="number">0</span>)</span><br><span class="line">    question, answer = list(data_df[<span class="string">'Q'</span>]),list(data_df[<span class="string">'A'</span>])</span><br><span class="line">    <span class="comment"># 학습 : 검증 = 67 : 33</span></span><br><span class="line">    train_input,eval_input,train_label,eval_label = train_test_split(question,answer,</span><br><span class="line">    test_size=<span class="number">0.33</span>,random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_input,train_label,eval_input,eval_label</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 <b>한글 테스트를 토크나이징</b>하기 위해<br>    <font color="hotpink"><b>형태소로 분리</b></font>하는 작업을 수행하는 함수이다<br>    해당 함수의 경우, 환경 설정 파일을 통해 <b>사용 여부를 선택</b>할 수 있다<br>    <br><br>    형태소로 분류한 데이터를 받아<br>    <font color="hotpink"><b>morphs 함수</b></font>를 통해 <b>토크나이징된 리스트 객체</b>를 받고<br>    <b>공백 문자를 기준으로 문자열로 재구성해 반환</b>한다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepro_like_morphlized</span><span class="params">(data)</span>:</span></span><br><span class="line">    morph_analyzer = Okt()</span><br><span class="line">    result_data = list()</span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> tqdm(data):</span><br><span class="line">        morphlized_seq = <span class="string">" "</span>.join(morph_analyzer.morphs(seq.replace(<span class="string">' '</span>,<span class="string">''</span>)))</span><br><span class="line">        result_data.append(morphlized_seq)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result_data</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 인코더에 적용될<br>    <font color="hotpink"><b>입력값을 만드는 전처리 함수</b></font>이다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># value : 전처리할 데이터</span></span><br><span class="line"><span class="comment"># dictionary : 단어 사전</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">enc_processing</span><span class="params">(value,dictionary)</span>:</span></span><br><span class="line">    <span class="comment"># 인덱스 값 가지고 있기 위한 배열</span></span><br><span class="line">    sequences_input_index = []</span><br><span class="line">    <span class="comment"># 인코딩 되는 문장의 길이 누적 배열</span></span><br><span class="line">    sequences_length = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 입력 데이터에 대해 전처리를 진행하는데,</span></span><br><span class="line">    <span class="comment"># [형태소 기준으로 토크나이징 / 단순히 띄어쓰기 기준으로 토크나이징]에 다라 처리 흐름이 나뉨</span></span><br><span class="line">    <span class="keyword">if</span> DEFINES.tokenize_as_morph:</span><br><span class="line">        value = prepro_like_morphlized(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> sequence <span class="keyword">in</span> value:</span><br><span class="line">        <span class="comment"># 정규 표현식 라이브러리를 통해 특수 문자 모두 제거</span></span><br><span class="line">        sequence = re.sub(CHANGE_FILTER,<span class="string">""</span>,sequence)</span><br><span class="line">        <span class="comment"># 하나의 문장을 인코딩할 때, 가지고 있기 위한 배열</span></span><br><span class="line">        sequence_index = []</span><br><span class="line">        <span class="comment"># 단어 사전을 이용해 각 단어 -&gt; 단어 인덱스</span></span><br><span class="line">        <span class="comment"># 만약 어떤 단어가 단어 사전에 포함되어 있지 않다면 UNK 토큰을 넣음</span></span><br><span class="line">        <span class="comment"># (UNK 토큰의 인덱스 값은 2로 설정했음)</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sequence.split():</span><br><span class="line">          <span class="comment"># 잘려진 단어가 딕셔너리에 존재하는지 보고</span></span><br><span class="line">          <span class="comment"># 그 값을 가져와 sequence_index에 추가</span></span><br><span class="line">            <span class="keyword">if</span> dictionary.get(word) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                sequence_index.extend([dictionary[word]])</span><br><span class="line">            <span class="comment"># 잘려진 단어가 딕셔너리에 존재하지 않는 경우이므로</span></span><br><span class="line">            <span class="comment"># UNK(2)를 넣어 줌</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sequence_index.extend([dictionary[UNK]])</span><br><span class="line">            <span class="comment"># 모델에 적용할 최대 길이보다 긴 문장의 경우 자름</span></span><br><span class="line">            <span class="keyword">if</span> len(sequence_index) &gt; DEFINES.max_sequence_length:</span><br><span class="line">                sequence_index = sequence_index[:DEFINES.max_sequence_length]</span><br><span class="line"></span><br><span class="line">            sequences_length.append(len(sequence_index))</span><br><span class="line">            <span class="comment"># 최대 길이보다 짧은 문장의 경우 문장의 뒷부분 패딩 처리</span></span><br><span class="line">            sequence_index += (DEFINES.max_sequence_length - len(sequence_index)) *</span><br><span class="line">            [dictionary[PAD]]</span><br><span class="line">            <span class="comment"># 인덱스화 되어있는 값을 sequence_input_index에 추가</span></span><br><span class="line">            sequence_input_index.append(sequence_index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># np.asarray(sequence_input_index) : 앞서 전처리한 데이터</span></span><br><span class="line">        <span class="comment"># sequences_length : 패딩 처리 전, 각 문장의 실제 길이를 담고 있는 리스트</span></span><br><span class="line">        <span class="comment"># 인덱스화된 일반 배열을 numpy 배열화</span></span><br><span class="line">        <span class="comment"># tensorflow 데이터셋에 넣어주기 위한 사전 작업</span></span><br><span class="line">        <span class="keyword">return</span> np.asarray(sequence_input_index), sequences_length</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 <font color="hotpink"><b>디코더 부분에 필요한 전처리 함수</b></font>를 만들어보자<br>    디코더에는 <b>두 가지 전처리 함수</b>가 사용된다<br>    <hr><br>      - 디코더의 <b>입력으로 사용</b> 될<br>        <font color="blue"><b>입력값을 만드는 전처리 함수</b></font><br>      - <b>디코더의 결과</b>로 학습을 위해 필요한 라벨,<br>        즉, <font color="blue"><b>타겟값을 만드는 전처리 함수</b></font><br>    <hr><br>    <b>입력값은 <font color="hotpink">START</font> 토큰</b>이 앞에 들어가 있고,<br>    <b>타깃값은 문장 끝에 <font color="hotpink">END</font> 토큰</b>이 들어가 있어야 한다<br>    <br><br>    먼저 디코더의 <font color="hotpink"><b>입력값을 만드는 함수</b></font>이다<br>    인코더 입력값 생성 전처리 함수와 <b>한 가지 다른 점</b>은<br>    각 <b>문장의 처음에 START 토큰</b>을 넣어준다는 점이다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 디코더의 입력으로 사용될 입력값을 만드는 전처리 함수</span></span><br><span class="line"><span class="comment"># "&lt;START&gt;,안녕,&lt;PADDING&gt;"</span></span><br><span class="line"><span class="comment"># value : 데이터 / dictionary : 단어 사전</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dec_input_processing</span><span class="params">(value, dictionary)</span>:</span></span><br><span class="line">    <span class="comment"># 인덱스 값들을 가지고 있는 배열</span></span><br><span class="line">    sequence_output_index = []</span><br><span class="line">    <span class="comment"># 디코딩 입력이 되는 문장의 길이 누적 배열</span></span><br><span class="line">    sequences_length = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 형태소 토크나이징 사용 유무</span></span><br><span class="line">    <span class="keyword">if</span> DEFINES.tokenize_as_morph:</span><br><span class="line">        value = prepro_like_morphlized(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> sequence <span class="keyword">in</span> value:</span><br><span class="line">        <span class="comment"># 정규화를 사용해 필터에 들어있는 값들을 ""로 치환</span></span><br><span class="line">        sequence = re.sub(CHANGE_FILTER,<span class="string">""</span>,sequence)</span><br><span class="line">        <span class="comment"># 디코딩 시, 하나의 문장을 가지고 있기 위한 배열</span></span><br><span class="line">        sequence_index = []</span><br><span class="line">        <span class="comment"># 디코딩 입력의 맨 앞에 START가 넣기</span></span><br><span class="line">        <span class="comment"># 스페이스 단위 별로 단어를 가져와 딕셔너리의 값(인덱스) 넣어줌</span></span><br><span class="line">        sequence_index = [dictionary[STD]] +</span><br><span class="line">        [dictionary[word] <span class="keyword">for</span> word <span class="keyword">in</span> sequence.split()]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 문장 제한 길이보다 길 경우, 자르기</span></span><br><span class="line">        <span class="keyword">if</span> len(sequence_index) &gt; DEFINES.max_sequence_length:</span><br><span class="line">            sequence_index = sequence_index[:DEFINES.max_sequence_length]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 입력 문장 길이 배열에 문장 길이 추가</span></span><br><span class="line">        sequences_length.append(len(sequence_index))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 문장 제한 길이보다 짧을 경우, 패딩</span></span><br><span class="line">        sequence_index += (DEFINES.max_sequence_length -</span><br><span class="line">         len(sequence_index)) * [dictionary[PAD]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 인덱스화 되어 있는 값을 인덱스값 배열에 추가</span></span><br><span class="line">        sequence_output_index.append(sequence_index)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 전처리한 데이터 / 각 데이터 문장의 실제 길이 리스트 리턴</span></span><br><span class="line">    <span class="keyword">return</span> np.asarray(sequence_output_index),sequences_length</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    <font color="hotpink"><b>타깃값을 만드는 전처리 함수</b></font> 역시 유사하나,<br>    문장의 시작부분에 <b>START 토큰을 넣지 않고</b><br>    <b>마지막에 END 토큰</b>을 넣는다는 차이점이 있다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 디코더의 결과로 학습에 필요한 라벨인 타깃값을 만드는 전처리 함수</span></span><br><span class="line"><span class="comment"># ex) "안녕, &lt;END&gt;,&lt;PADDING&gt;"</span></span><br><span class="line"><span class="comment"># 시작 토큰 넣지 X, 마지막에 종료 토큰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dec_target_processing</span><span class="params">(value,dictionary)</span>:</span></span><br><span class="line">    <span class="comment"># 인덱스 값을 가지고 있는 누적 배열</span></span><br><span class="line">    sequences_target_index = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 형태소 토크나이징 사용 유무</span></span><br><span class="line">    <span class="keyword">if</span> DEFINES.tokenize_as_morph:</span><br><span class="line">        value = prepro_like_morphlized(value)</span><br><span class="line">    <span class="keyword">for</span> sequence <span class="keyword">in</span> value:</span><br><span class="line">        sequence = re.sub(CHANGE_FILTER,<span class="string">""</span>,sequence)</span><br><span class="line">        <span class="comment"># 문장에서 스페이스 단위 별로 단어를 가져와</span></span><br><span class="line">        <span class="comment"># 딕셔너리의 값인 인덱스를 넣어준다</span></span><br><span class="line">        sequence_index = [dictionary[word] <span class="keyword">for</span> word <span class="keyword">in</span> sequence.split()]</span><br><span class="line">        <span class="comment"># 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자른다</span></span><br><span class="line">        <span class="comment"># 마지막에 END 토큰을 넣어준다</span></span><br><span class="line">        <span class="keyword">if</span> len(sequence_index) &gt;= DEFINES.max_sequence_length:</span><br><span class="line">            sequence_index =sequence_index[:DEFINES.max_sequence_length<span class="number">-1</span>] +</span><br><span class="line">            [dictionary[END]]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sequence_index += [dictionary[END]]</span><br><span class="line"></span><br><span class="line">        sequence_index += (DEFINES.max_sequence_length - len(sequence_index)) *</span><br><span class="line">        [dictionary[PAD]]</span><br><span class="line"></span><br><span class="line">        sequences_target_index.append(sequence_index)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 인덱스화된 일반 배열을 numpy 배열로 변환한다</span></span><br><span class="line">    <span class="comment"># 실제 길이를 담고 있는 리스트의 경우 따로 만들지 X</span></span><br><span class="line">    <span class="keyword">return</span> np.asarray(sequences_target_index)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음으로 살펴 볼 함수는<br>    <font color="hotpink"><b>학습한 모델을 통해 예측할 때 사용하는 함수</b></font>이다<br>    인덱스 값들을 실제 단어로 바꾸어야<br>    성능 확인이나 실제 챗봇 용도 사용이 가능하기 때문에<br>    <b>인덱스로 이루어진 문장</b>을 <b>실제 단어들의 문자열로</b> 만드는 함수를 정의한다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습한 모델을 통해 예측할 때 사용하는 함수</span></span><br><span class="line"><span class="comment"># index -&gt; string 변경 함수</span></span><br><span class="line"><span class="comment"># 예측 결과는 각 단어의 인덱스 벡터로 나올 것</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pred2string</span><span class="params">(value, dictionary)</span>:</span></span><br><span class="line">  <span class="comment"># 텍스트 문장 보관 배열</span></span><br><span class="line">  sentence_string = []</span><br><span class="line">  <span class="comment"># 단어 사전 사용해 인덱스 데이터 -&gt; 실제 단어 -&gt; 문자열</span></span><br><span class="line">  <span class="keyword">for</span> v <span class="keyword">in</span> value:</span><br><span class="line">      sentence_string = [dictionary[index] <span class="keyword">for</span> index <span class="keyword">in</span> v[<span class="string">'indexs'</span>]]</span><br><span class="line"></span><br><span class="line">  print(sentence_string)</span><br><span class="line">  answer = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 패딩과 종료 토큰의 경우 바꾸지 X , 공백으로 처리</span></span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> sentence_string:</span><br><span class="line">      <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> PAD <span class="keyword">and</span> word <span class="keyword">not</span> <span class="keyword">in</span> END:</span><br><span class="line">          answer += word</span><br><span class="line">          answer += <span class="string">" "</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 결과 출력</span></span><br><span class="line">  print(answer)</span><br><span class="line">  <span class="keyword">return</span> answer</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    계속해서 파라미터로 사용하고 있는 <b><font color="hotpink">단어사전</font> 역시 함수를 통해 직접 만들어야</b> 한다<br>    단어 사전을 만들기 위해서는<br>    <font color="hotpink"><b>데이터를 전처리한 후 단어 리스트로 만드는 함수</b></font>가 필요하다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 단어 사전 생성을 위한</span></span><br><span class="line"><span class="comment"># 데이터를 전처리한 후 단어 리스트로 만드는 함수</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_tokenizer</span><span class="params">(data)</span>:</span></span><br><span class="line">  <span class="comment"># 정규 표현식을 사용해 특수 기호를 모두 제거하고</span></span><br><span class="line">  <span class="comment"># 단어들을 기준으로 나눠</span></span><br><span class="line">  <span class="comment"># 전체 데이터의 모든 단어를 포함하는 단어 리스트로 만듦</span></span><br><span class="line">  words = []</span><br><span class="line">  <span class="keyword">for</span> sentence <span class="keyword">in</span> data:</span><br><span class="line">      sentence = re.sub(CHANGE_FILTER,<span class="string">""</span>,sentence)</span><br><span class="line">      <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split():</span><br><span class="line">          words.append(word)</span><br><span class="line">  <span class="comment"># 토크나이징 &amp; 정규표현식 통해 만들어진 값 리턴</span></span><br><span class="line">  <span class="keyword">return</span> [word <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> word]</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 <font color="hotpink"><b>단어 사전을 만드는 함수</b></font>이다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 단어 사전 만드는 함수</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_vocabulary</span><span class="params">()</span>:</span></span><br><span class="line">  vocabulary_list = [] <span class="comment"># 사전을 담을 배열</span></span><br><span class="line">  <span class="comment"># 경로에 사전 파일이 있다면 불러와서 사용</span></span><br><span class="line">  <span class="comment"># 없다면 만드는 구조</span></span><br><span class="line">  <span class="comment"># &gt;&gt; 데이터 불러와서 앞서 정의한 함수를 통해</span></span><br><span class="line">  <span class="comment">#    데이터를 토크나이징해 단어 리스트로 만듦</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">not</span>(os.path.exists(DEFINES.vocabulary_path))):</span><br><span class="line">    <span class="comment"># 이미 생성된 사전 파일이 존재하지 않으므로 새로 만듦</span></span><br><span class="line">      <span class="keyword">if</span> (os.path.exists(DEFINES.data_path)):</span><br><span class="line">        <span class="comment"># 데이터가 존재한다면 데이터 불러오기</span></span><br><span class="line">          data_df = pd.read_csv(DEFINES.data_path, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">          <span class="comment"># 질문과 답에 대한 열 가져오기</span></span><br><span class="line">          question, anwser = list(data_df[<span class="string">'Q'</span>]),list(data_df[<span class="string">'A'</span>])</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 형태소에 따른 토크나이즈 처리</span></span><br><span class="line">          <span class="keyword">if</span> DEFINES.tokenize_as_morph:</span><br><span class="line">              question = prepro_like_morphlized(question)</span><br><span class="line">              answer = prepro_like_morphlized(answer)</span><br><span class="line">          data = []</span><br><span class="line">          <span class="comment"># 질문과 답변을 구조가 없는 배열로 만듦</span></span><br><span class="line">          data.extend(question)</span><br><span class="line">          data.extend(answer)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 토크나이저 처리 부분</span></span><br><span class="line">          words = data_tokenizer(data)</span><br><span class="line">          <span class="comment"># set 데이터 타입을 사용해 중복을 제거한 후, 단어 리스트로 만듦</span></span><br><span class="line">          words = list(set(words))</span><br><span class="line">          <span class="comment"># MARKER로 사전에 정의한 특정 토큰들을 단어 리스트 앞에 추가</span></span><br><span class="line">          words[:<span class="number">0</span>] = MARKER</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 리스트로 만든 사전을 파일로 저장</span></span><br><span class="line">      <span class="keyword">with</span> open(DEFINES.vocabulary_path,<span class="string">"w"</span>) <span class="keyword">as</span> vocabulary_file:</span><br><span class="line">              <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                  vocabulary_file.write(word + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 사전 파일이 존재하면 불러와 배열에 넣어줌</span></span><br><span class="line">  <span class="keyword">with</span> open(DEFINES.vocabulary_path,<span class="string">"r"</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> vocabulary_file:</span><br><span class="line">      <span class="keyword">for</span> line <span class="keyword">in</span> vocabulary_file:</span><br><span class="line">          vocabulary_list.append(line.strip())</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 배열의 내용을 딕셔너리 구조로 만듦 (key-value 구조)</span></span><br><span class="line">  word2idx, idx2word = make_vocabulary(vocabulary_list)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># word2idx : 단어에 대한 인덱스를 가진 딕셔너리</span></span><br><span class="line">  <span class="comment"># idx2word : 인덱스에 대한 단어를 가진 딕셔너리</span></span><br><span class="line">  <span class="comment"># len(word2idx) = 단어의 개수</span></span><br><span class="line">  <span class="keyword">return</span> word2idx,idx2word,len(word2idx)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 <b>두개의 딕셔너리 <font color="hotpink">word2idx</font>와 <font color="hotpink">idx2word</font>를 만드는 함수</b>이다<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_vocabulary</span><span class="params">(vocabulary_list)</span>:</span></span><br><span class="line">    <span class="comment"># 파라미터로 받은 단어 리스트로 두 개의 딕셔너리를 만듦</span></span><br><span class="line">    <span class="comment"># 단어에 대한 인덱스 딕셔너리 생성</span></span><br><span class="line">    word2idx = &#123;word: idx <span class="keyword">for</span> idx, word <span class="keyword">in</span> enumerate(vocabulary_list)&#125;</span><br><span class="line">    <span class="comment"># 인덱스에 대한 단어 딕셔너리 생성</span></span><br><span class="line">    idx2word = &#123;idx: word <span class="keyword">for</span> idx, word <span class="keyword">in</span> enumerate(vocabulary_list)&#125;</span><br><span class="line">    <span class="keyword">return</span> word2idx, idx2word</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    다음은 tensorflow 모델에 데이터를 적용하기 위한<br>    데이터 입력 함수이다<br>    <font size="2">(Estimator를 이용한 모델에 적용을 위한 함수)</font><br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습에 들어가 배치 데이터를 만드는 함수</span></span><br><span class="line"><span class="comment"># 파라미터 : 인코더에 적용될 입력값, 디코더에 적용될 입력값, 학습 시 디코더에서 사용될 타깃값, 배치 크기</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_input_fn</span><span class="params">(train_input_enc,train_output_dec,train_target_dec,batch_size)</span>:</span></span><br><span class="line">    <span class="comment"># dataset을 생성하는 부분</span></span><br><span class="line">    <span class="comment"># from_tensor_slices : 각각 한 문장으로 자르기</span></span><br><span class="line">    <span class="comment"># train_input_enc, train_output_dec, train_target_dec를</span></span><br><span class="line">    <span class="comment"># 각각 한 문장으로 나눈다!</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices((train_input_enc,train_output_dec,train_target_dec))</span><br><span class="line">    <span class="comment"># 전체 데이터 섞기</span></span><br><span class="line">    dataset = dataset.shuffle(buffer_size==len(train_input_enc))</span><br><span class="line">    <span class="comment"># 배치 크기를 파라미터로 전달하지 않을 경우, 에러 발생 시킴</span></span><br><span class="line">    <span class="keyword">assert</span> batch_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>, <span class="string">"train batchSize must not be None"</span></span><br><span class="line">    <span class="comment"># 한 문장씩 나눈 것을 배치 사이즈 만큼 묶어 줌</span></span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    <span class="comment"># 데이터의 각 요소를 변환해 맵으로 구성</span></span><br><span class="line">    dataset = dataset.map(rearrange)</span><br><span class="line">    <span class="comment"># 파라미터로 에폭 수를 전달해</span></span><br><span class="line">    <span class="comment"># 에폭 수 만큼 반복하게 함</span></span><br><span class="line">    <span class="comment"># 파라미터를 주지 않았으므로 무한히 반복</span></span><br><span class="line">    <span class="comment"># 사용자가 손실값이 적당히 떨어졌다고 판단되면 직접 멈추는 것이 가능</span></span><br><span class="line">    dataset = dataset.repeat()</span><br><span class="line">    <span class="comment"># iterator 생성</span></span><br><span class="line">    iterator = dataset.make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterator를 통해 다음 항목의 개체를 넘겨 줌</span></span><br><span class="line">    <span class="keyword">return</span> iterator.get_next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 평가에 들어가 배치 데이터를 만드는 함수</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_input_fn</span><span class="params">(eval_input_enc,eval_output_dec,eval_target_dec,batch_size)</span>:</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices((eval_input_enc,eval_output_dec,eval_target_dec))</span><br><span class="line">    dataset = dataset.shuffle(buffer_size==len(eval_input_enc))</span><br><span class="line">    <span class="keyword">assert</span> batch_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>, <span class="string">"eval batchSize must not be None"</span></span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    dataset = dataset.map(rearrange)</span><br><span class="line">    <span class="comment"># 평가이므로 반복을 수행하지 X 1회만 동작</span></span><br><span class="line">    dataset = dataset.repeat(<span class="number">1</span>)</span><br><span class="line">    iterator = dataset.make_one_shot_iterator()</span><br><span class="line">    <span class="keyword">return</span> iterator.get_next()</span><br><span class="line">    </span><br></pre></td></tr></table></figure><br>    마지막으로 <font color="hotpink"><b>맵 함수</b></font>를 정의해보자<br>    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파라미터 : 인코더 적용 입력값, 디코더 적용 입력값, 라벨로 학습 시 적용되는 타깃값</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rearrange</span><span class="params">(input,output,target)</span>:</span></span><br><span class="line">    <span class="comment"># 두 개의 입력값을 딕셔너리 형태로 묶음</span></span><br><span class="line">    features = &#123;<span class="string">"input"</span>:input,<span class="string">"output"</span>:output&#125;</span><br><span class="line">    <span class="keyword">return</span> features, target</span><br></pre></td></tr></table></figure><br>    <br><br>    <div id="section5"><br>    <font size="4" color="blue"><b>[model]</b></font><br>    <hr color="blue"><br>    <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>      <font color="purple" size="4"><b>Sequence to Sequence</b></font> 모델을 기반으로 만들 것이며,<br>      해당 모델의 중간에 사용되는 신경망으로는<br>      <b>재현 신경망</b> 중,<br>      <font color="hotpink"><b>LSTM</b></font><font size="2">(Long-Short Term Memory)</font> 모델을 사용하겠다<br>      <br><br>      해당 파일에는 <b>실제로 사용할 모델이 정의</b>되어 있으며,<br>      총 <b>[2개의 함수]</b>가 존재한다<br>      <hr><br>      - <font color="blue">모델을 정의</font>한 함수<font size="2">(model)</font><br>      - 한 스텝마다 적용되는 <font color="blue">LSTM과 dropout을 합쳐 하나로 모듈화</font>한 함수<font size="2">(make_lstm_cell)</font><br>      <hr><br>      다음은 <font color="hotpink"><b>LSTM과 dropout을 모듈화한 함수</b></font>이다<br>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> DEFINES</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># mode : 현재 모델이 작동 중인 모드</span></span><br><span class="line"><span class="comment"># hiddenSize : LSTM의 은닉 상태 벡터값의 차원</span></span><br><span class="line"><span class="comment"># index : 여러 개의 LSTM 스텝을 만들기 때문에, 각 스텝의 인덱스 값</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_lstm_cell</span><span class="params">(mode, hiddenSize, index)</span>:</span></span><br><span class="line">  cell = tf.nn.rnn_cell.BasicLSTMCell(hiddenSize,name=<span class="string">"lstm"</span>+str(index))</span><br><span class="line">  <span class="comment"># 모드를 확인해 학습 중이라면,</span></span><br><span class="line">  <span class="comment"># RNN에 적용시키는 dropout 적용</span></span><br><span class="line">  <span class="comment"># 적용할 dropout 혹률은 사전에 정의한 값으로 받음</span></span><br><span class="line">  <span class="keyword">if</span> mode == tf.estimator.ModeKeys.TRAIN:</span><br><span class="line">      cell =tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob = DEFINES.dropout_width)</span><br><span class="line">  <span class="keyword">return</span> cell</span><br></pre></td></tr></table></figure><br>      본격적으로 <font color="hotpink"><b>모델 함수</b></font>를 살펴보자<br>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># features : 모델 입력 함수를 통해 만든 피처 값 전달</span></span><br><span class="line"><span class="comment">#            (딕셔너리 형태 : 인코더 입력 &amp; 디코더 입력)</span></span><br><span class="line"><span class="comment"># label : 디코더의 타깃값</span></span><br><span class="line"><span class="comment"># mode : 모델의 상태 (학습 / 검증 / 평가)</span></span><br><span class="line"><span class="comment"># params : 모델에 적용되는 몇 가지 인자 값을 딕셔너리 형태로 전달 받음</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(features, labels, mode, params)</span>:</span></span><br><span class="line">  <span class="comment"># 모델 함수에 적용된 모드가 어떤 상태인지 각각 상수값으로 설정</span></span><br><span class="line">  TRAIN = mode == tf.estimator.ModeKeys.TRAIN</span><br><span class="line">  EVAL = mode == tf.estimator.ModeKeys.EVAL</span><br><span class="line">  PREDICT = mode == tf.estimator.ModeKeys.PREDICT</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ------------------- 본격적인 모델 시작 -------------------------</span></span><br><span class="line">  <span class="comment"># 인코더 / 디코더 구현 이전에 입력값을 모델에 적용할 수 있도록 벡터화</span></span><br><span class="line">  <span class="comment"># 두 가지 선택지를 모델 함수에 적용되는 파라미터값을 사용해 선택하도록 함</span></span><br><span class="line">  <span class="comment"># 임베딩을 사용하는 경우 / 원-핫 인코딩 사용하는 경우 나눠 각 임베딩 행렬 생성</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ----------------------------인코더-----------------------------</span></span><br><span class="line">  <span class="comment"># &lt;임베딩을 사용하는 경우&gt;</span></span><br><span class="line">  <span class="keyword">if</span> params[<span class="string">'embedding'</span>] == <span class="keyword">True</span>:</span><br><span class="line">      <span class="comment"># 행렬 초기화 방법 미리 정의 : Xavier(자비어) 방식</span></span><br><span class="line">      initializer = tf.contrib.layers.xavier_initializer()</span><br><span class="line">      <span class="comment"># 임베딩 행렬 만들기</span></span><br><span class="line">      embedding_encoder = tf.get_variable(name=<span class="string">"embedding_encoder"</span>,</span><br><span class="line">                                   shape = [params[<span class="string">'vocabulary_length'</span>],</span><br><span class="line">                                           params[<span class="string">'embedding_size'</span>]],</span><br><span class="line">                                          dtype = tf.float32,</span><br><span class="line">                                          initializer = initializer,</span><br><span class="line">                                          trainable = <span class="keyword">True</span>)</span><br><span class="line">  <span class="comment"># &lt;임베딩을 사용하지 않는 경우&gt;</span></span><br><span class="line">  <span class="comment"># 임베딩 행렬을 단순 단위 행렬로 정의, 파라미터 설정을 통해</span></span><br><span class="line">  <span class="comment"># 학습이 안되도록 함</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      embedding_encoder = tf.eye(num_rows = params[<span class="string">'vocabulary_length'</span>], dtype = tf.float32)</span><br><span class="line">      embedding_encoder = tf.get_variable(name = <span class="string">"embedding_encoder"</span>,</span><br><span class="line">                                         initializer = embedding_encoder,</span><br><span class="line">                                         trainable = <span class="keyword">False</span>)</span><br><span class="line">  <span class="comment"># embedding_lookup 함수를 통해</span></span><br><span class="line">  <span class="comment"># 각 단어를 임베딩 벡터로 만듦</span></span><br><span class="line">  embedding_encoder_batch = tf.nn.embedding_lookup(params = embedding_encoder,</span><br><span class="line">                                                  ids = features[<span class="string">'input'</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ----------------------------디코더-----------------------------</span></span><br><span class="line">  <span class="comment"># &lt;임베딩을 사용하는 경우&gt;</span></span><br><span class="line">  <span class="keyword">if</span> params[<span class="string">'embedding'</span>] == <span class="keyword">True</span>:</span><br><span class="line">      <span class="comment"># 행렬 초기화 방법 미리 정의</span></span><br><span class="line">      initializer = tf.contrib.layers.xavier_initializer()</span><br><span class="line">      embedding_decoder = tf.get_variable(name = <span class="string">"embedding_decoder"</span>,</span><br><span class="line">                                          shape = [params[<span class="string">'vocabulary_length'</span>],</span><br><span class="line">                                           params[<span class="string">'embedding_size'</span>]],</span><br><span class="line">                                          dtype = tf.float32,</span><br><span class="line">                                          initializer = initializer,</span><br><span class="line">                                          trainable = <span class="keyword">True</span>)</span><br><span class="line">  <span class="comment"># &lt;임베딩을 사용하지 않는 경우&gt;</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      embedding_decoder = tf.eye(num_rows = params[<span class="string">'vocabulary_length'</span>], dtype = tf.float32)</span><br><span class="line">      embedding_decoder = tf.get_variable(name = <span class="string">"embedding_decoder"</span>,</span><br><span class="line">                                         initializer = embedding_decoder,</span><br><span class="line">                                         trainable = <span class="keyword">False</span>)</span><br><span class="line">  embedding_decoder_batch = tf.nn.embedding_lookup(params = embedding_decoder,</span><br><span class="line">                                                  ids = features[<span class="string">'output'</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ========================인코더 부분 구현=======================</span></span><br><span class="line">  <span class="comment"># LSTM 신경망 생성</span></span><br><span class="line">  <span class="comment"># 인자로 전달되는 params의 multilayer 사용 여부에 따라</span></span><br><span class="line">  <span class="comment"># 두 가지 방법 중 하나로 구현 됨</span></span><br><span class="line">  <span class="keyword">with</span> tf.Variable_scope(<span class="string">'encoder_scope'</span>,reuse=tf.AUTO_REUSE):</span><br><span class="line">  <span class="comment"># multylayer 사용 : 사전에 정의한 make_lstm_cell 함수를 layer 수 만큼 반복해 리스트로 만듦</span></span><br><span class="line">      <span class="keyword">if</span> params[<span class="string">'multilayer'</span>] == <span class="keyword">True</span>:</span><br><span class="line">          encoder_cell_list = [make_lstm_cell(mode,params[<span class="string">'hidden_size'</span>],i) <span class="keyword">for</span> i <span class="keyword">in</span> range(params[<span class="string">'layer_size'</span>])]</span><br><span class="line">          rnn_cell = tf.contrib.rnn.MultiRNNCell(encoder_cell_list)</span><br><span class="line">  <span class="comment"># multilayer 사용 X : 함수를 한번만 호출</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          rnn_cell = make_lstm_cell(mode,params[<span class="string">'hidden_size'</span>],<span class="string">""</span>)</span><br><span class="line">  <span class="comment"># 이렇게 만든 LSTM 신경망을</span></span><br><span class="line">  <span class="comment"># 입력값과 함께 tensorflow의 dynamic_rnn 함수에 적용</span></span><br><span class="line">  encoder_outputs, encoder_states = tf.nn.dynamic_rnn(cell=rnn_cell,</span><br><span class="line">                                                      inputs = embedding_encoder_batch,dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># ========================디코더 부분 구현=======================</span></span><br><span class="line">  <span class="keyword">with</span> tf.Variable_scope(<span class="string">'decoder_scope'</span>,reuse=tf.AUTO_REUSE):</span><br><span class="line">      <span class="keyword">if</span> params[<span class="string">'multilayer'</span>] == <span class="keyword">True</span>:</span><br><span class="line">          decoder_cell_list = [make_lstm_cell(mode,params[<span class="string">'hidden_size'</span>],i) <span class="keyword">for</span> i <span class="keyword">in</span> range(params[<span class="string">'layer_size'</span>])]</span><br><span class="line">          rnn_cell = tf.contrib.rnn.MultiRNNCell(decoder_cell_list)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          rnn_cell = make_lstm_cell(mode,params[<span class="string">'hidden_size'</span>],<span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># LSTM의 첫 스텝 은닉 상태 벡터 값을</span></span><br><span class="line">      <span class="comment"># 인코더의 마지막 스텝 은닉 상태 벡터값(encoder_states)로 초기화</span></span><br><span class="line">      decoder_initial_state = encoder_states</span><br><span class="line">      decoder_outputs, decoder_states = tf.nn.dynamic_rnn(cell=rnn_cell,</span><br><span class="line">                                                          inputs = embedding_decoder_batch,</span><br><span class="line">                                                          initial_state = decoder_initial_state,</span><br><span class="line">                                                          dtype=tf.float32)</span><br><span class="line">  <span class="comment"># 디코더의 결괏값에 Dense 층 적용</span></span><br><span class="line">  <span class="comment"># 결괏값의 차원을 단어의 수만큼 변경하기 위함</span></span><br><span class="line">  logits = tf.keras.layer.Dense(params[<span class="string">'vocabulary_length'</span>])(decoder_outputs)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># logits으로 출력단어(결괏값)을 뽑아야 함</span></span><br><span class="line">  <span class="comment"># Dense 층을 통해 차원을 단어 개수만큼 늘렸기 때문에</span></span><br><span class="line">  <span class="comment"># 최댓값을 가지는 위치의 단어를 출력하면 됨</span></span><br><span class="line">  predict = tf.argmax(logits,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 현재 [실행 모드가 예측 상태]면</span></span><br><span class="line">  <span class="comment"># 손실값 계산, 최적화가 필요 없으므로 바로 return</span></span><br><span class="line">  <span class="keyword">if</span> PREDICT:</span><br><span class="line">      <span class="comment"># 예측값을 딕셔너리 형태로 저장</span></span><br><span class="line">      prediction = &#123;</span><br><span class="line">          <span class="string">'indexs'</span> : predict,</span><br><span class="line">          <span class="string">'logits'</span> : logits</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment"># Estimator 객체로 return</span></span><br><span class="line">      <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode,predictions = predictions)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># [상태가 학습, 평가 일때만 진행되는 부분]</span></span><br><span class="line">  <span class="comment"># 실제 라벨값과 비교해서 loss 값을 뽑은 후</span></span><br><span class="line">  <span class="comment"># 이 값을 이용해 모델을 학습할 것</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 각 라벨 값을 원-핫 인코딩 벡터로 만듦</span></span><br><span class="line">  labels_ = tf.one_hot(labels, params[<span class="string">'vocabulary_length'</span>])</span><br><span class="line">  <span class="comment"># 라벨과 모델의 결괏값을 사용해 손실값을 만듦</span></span><br><span class="line">  <span class="comment"># softmax_cross_entropy_with_logits_v2 함수 사용</span></span><br><span class="line">  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=labels_))</span><br><span class="line">  <span class="comment"># 구한 loss 값을 사용해 모델의 성능 측정</span></span><br><span class="line">  <span class="comment"># 측정한 정확도는 딕셔너리 형태로 저장 후,</span></span><br><span class="line">  <span class="comment"># 이후 Estimator의 return 값으로 전달할 것</span></span><br><span class="line">  accuracy = tf.metrics.accuracy(labels = labels, predictions = predict, name=<span class="string">"acc0p"</span>) <span class="comment"># 정확도 측정</span></span><br><span class="line">  <span class="comment"># 딕셔너리 형태로 정의</span></span><br><span class="line">  metrics = &#123;<span class="string">'accuracy'</span>: accuracy&#125;</span><br><span class="line">  <span class="comment"># 학습 과정의 내용을 저장 하도록 tf.summary.scalar에 정확도 값 제공</span></span><br><span class="line">  tf.summary.scalar(<span class="string">'accuracy'</span>,accuracy[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># [평가 모드인 경우] 함수 리턴</span></span><br><span class="line">  <span class="keyword">if</span> EVAL:</span><br><span class="line">      <span class="comment"># 손실값과 모델 성능 측정값(정확도 딕셔너리)을 리턴</span></span><br><span class="line">      <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=metrics)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># [학습 모드인 경우]</span></span><br><span class="line">  <span class="comment"># 손실값을 단순히 계산하는 것 뿐만 아니라 가중치 최적화 과정이 필요</span></span><br><span class="line">  <span class="comment"># 가중치 최적화 후, 최종적으로 함수 리턴</span></span><br><span class="line">  <span class="keyword">assert</span> TRAIN <span class="comment"># 학습 상태가 아닌 경우 에러 발생하도록</span></span><br><span class="line">  <span class="comment"># adam optimizer 사용</span></span><br><span class="line">  optimizer = tf.train.AdamOptimizer(learning_rate=DEFINES.learning_rate)</span><br><span class="line">  <span class="comment"># 정의한 객체에 minimize 함수 실행해 최적화 짖ㄴ행</span></span><br><span class="line">  <span class="comment"># 파라미터로 손실값 전달</span></span><br><span class="line">  train_op = optimizer.minimize(loss,global_step = tf.train.get_global_step())</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode,loss=loss,train_op = train_op)</span><br><span class="line"></span><br><span class="line">      </span><br></pre></td></tr></table></figure><br>    </div><br>    <div id="section6"><br>    <font size="4" color="blue"><b>[main]</b></font><br>    <hr color="blue"><br>    <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>      지금까지 정의한 모듈을 실행해<br>      <font color="hotpink"><b>실제 학습을 진행하기 위한 main 파일</b></font>의 코드를 살펴보자<br>      <br><br>      우선 <b>데이터를 불러오고</b>,<br>      해당 <b>데이터를 <font color="hotpink">학습 데이터</font>와 <font color="hotpink">평가 데이터</font>로 나눠</b> 모델에 적용할 수 있도록 한다<br>      이후 <b><font color="hotpink">Estimator</font>를 정의</b>하고<br>      모델 <b><font color="hotpink">학습</font>과 <font color="hotpink">평가</font>를 진행</b>한다<br>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># model 파일 불러오기</span></span><br><span class="line"><span class="keyword">import</span> model <span class="keyword">as</span> ml</span><br><span class="line"><span class="comment"># data 파일 불러오기</span></span><br><span class="line"><span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> DEFINES</span><br><span class="line"></span><br><span class="line">DATA_OUT_PATH = <span class="string">"./data_out/"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">  <span class="comment"># 폴더를 확인하고 생성</span></span><br><span class="line">  <span class="comment"># DATA_OUT_PATH로 지정한 경로가 없다면 생성</span></span><br><span class="line">  <span class="comment"># 있다면 그대로 사용</span></span><br><span class="line">  data_out_path = os.path.join(os.getcwd(),DATA_OUT_PATH)</span><br><span class="line">  os.makedirs(data_out_path,exist_ok=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 앞서 정의한 load_vocabulary()와 load_data() 사용</span></span><br><span class="line">  <span class="comment"># 단어 사전과 데이터 불러오기</span></span><br><span class="line">  word2idx, idx2word, vocabulary_length = data.load_vocabulary()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 불러온 데이터를 활용해 모델 학습 시 적용이 가능하도록</span></span><br><span class="line">  <span class="comment"># 인코더 입력 데이터, 디코더 입력 데이터, 디코더 타깃 데이터로 만들기</span></span><br><span class="line">  train_input, train_label, eval_input, eval_label = data.load_data()</span><br><span class="line">  train_input_enc, train_input_enc_length = data.enc_processing(train_input,word2idx)</span><br><span class="line">  train_input_dec, train_input_dec_length = data.dec_input_processing(train_label,word2idx)</span><br><span class="line">  train_target_dec = data.dec_target_processing(train_label,word2idx)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 평가 데이터 만들기</span></span><br><span class="line">  eval_input_enc, eval_input_enc_length = data.enc_processing(eval_input,word2idx)</span><br><span class="line">  eval_input_dec, eval_input_dec_length = data.dec_input_processing(eval_label,word2idx)</span><br><span class="line">  eval_target_dec = data.dec_target_processing(eval_label,word2idx)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 학습, 평가에 필요한 모든 데이터가 준비 되었으므로</span></span><br><span class="line">  <span class="comment"># 모델 선언 후, 데이터를 적용해 학습과 평가 진행하면 OK!</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 학습 과정을 저장하고 기록이 가능하도록</span></span><br><span class="line">  <span class="comment"># 체크 포인터를 저장할 폴더 설정</span></span><br><span class="line">  <span class="comment"># 체크 포인트는 data_out 폴더 안에 생성하도록 되어 있음</span></span><br><span class="line">  check_point_path = op.path.join(os.getcwd(),DEFINES.check_point_path)</span><br><span class="line">  os.makedirs(check_point_path, exist_ok=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Estimator 객체 생성</span></span><br><span class="line">  <span class="comment"># model_fn : 모델 함수</span></span><br><span class="line">  <span class="comment"># model_dir : 체크 포인트를 저장할 경로</span></span><br><span class="line">  <span class="comment"># params : 모델에 필요한 인자값들</span></span><br><span class="line">  classifier = tf.estimator.Estimator(</span><br><span class="line">      model_fn = ml.model,</span><br><span class="line">      model_dir = DEFINES.check_point_path,</span><br><span class="line">      params = &#123;</span><br><span class="line">          <span class="string">'hidden_size'</span> : DEFINES.hidden_size,</span><br><span class="line">          <span class="string">'layer_size'</span> : DEFINES.layer_size,</span><br><span class="line">          <span class="string">'learning_rate '</span>: DEFINES.learning_rate,</span><br><span class="line">          <span class="string">'vocabulary_length'</span> : DEFINES.vocabulary_length,</span><br><span class="line">          <span class="string">'embedding_size'</span> : DEFINES.embedding_size,</span><br><span class="line">          <span class="string">'embedding'</span> : DEFINES.embedding,</span><br><span class="line">          <span class="string">'multilayer'</span> : DEFINES.multilayer</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Estimator 이용해 학습 진행</span></span><br><span class="line">  <span class="comment"># input_fn : 입력함수 -&gt; 앞서 정의한 학습 입력 함수 사용</span></span><br><span class="line">  <span class="comment"># steps: 스텝</span></span><br><span class="line">  classifier.train(input_fn=<span class="keyword">lambda</span>:data.train_input_fn(</span><br><span class="line">  train_input_enc,train_input_dec,train_target_dec,DEFINES.batch_size),</span><br><span class="line">                  steps = DEFINES.train_steps)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 학습이 끝나면 바로 모델 평가 진행을 위해 검증 함수 정의</span></span><br><span class="line">  <span class="comment"># input_fn : 검증 입력 함수</span></span><br><span class="line">  <span class="comment"># 바로 모델의 성능 확인이 가능하도록 콘솔에서 정확도 출력</span></span><br><span class="line">  eval_result = classifier.evaluate(input_fn=<span class="keyword">lambda</span>:data.eval_input_fn(</span><br><span class="line">  eval_input_enc,eval_input_dec,eval_target_dec,DEFINES.batch_size))</span><br><span class="line">  print(<span class="string">"\nEVAL set accuracy: &#123;accuracy: 0.3f&#125;\n"</span>.format(**eval_result))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 예시 문장을 이용해 모델의 결과가 어떤지 평가</span></span><br><span class="line">  <span class="comment"># 예시 문장 정의하고 인코더에 적용할 수 있도록 인코더 전처리 함수에 적용</span></span><br><span class="line">  predic_input_enc, predic_input_enc_length = data.enc_processing([<span class="string">"가끔 궁금해"</span>],word2idx)</span><br><span class="line">  <span class="comment"># 평가 시에는 디코더의 입력값으로 어떤 값도 들어가지 X</span></span><br><span class="line">  <span class="comment"># 빈 문자열 리스트를 넣어 디코더 입력값 전처리</span></span><br><span class="line">  predic_input_dec, predic_input_dec_length = data.dec_input_processing([<span class="string">""</span>],word2idx)</span><br><span class="line">  <span class="comment"># 학습 과정이 아니므로 디코더 출력 부분도 존재하지 X</span></span><br><span class="line">  predic_target_dec = data.dec_target_processing([<span class="string">""</span>],word2idx)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 예측 진행</span></span><br><span class="line">  predictions = classifier.predict(</span><br><span class="line">  input_fn=<span class="keyword">lambda</span>:data.eval_input_fn(predic_input_enc,predic_input_dec,predic_target_dec,DEFINES.batch_size))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 인덱스로 저장된 결과를 다시 문자열로 만들어 출력</span></span><br><span class="line">  data.pred2string(predictions,idx2word)</span><br><span class="line">      </span><br></pre></td></tr></table></figure><br>      <b>명령행에서 main 함수를 직접 실행할 수 있도록</b> 하단의 코드를 추가한다<br>      조건문을 사용해 작성된 코드가 바로 실행될 수 있게 하는데,<br>      <b>tensorflow의 log 수준</b>을 설정한 뒤<br>      <b>app.run함수</b>를 사용해 main 함수를 실행한다<br>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">  tf.app.run(main)</span><br><span class="line">tf.logging.set_verbosity</span><br><span class="line">      </span><br></pre></td></tr></table></figure><br>    </div><br>    <div id="section7"><br>    <font size="4" color="blue"><b>[predict]</b></font><br>    <hr color="blue"><br>    <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>      사용자에게 문장을 받아<br>      Estimator를 통해 <font color="hotpink"><b>&lt;예측한 문장을 출력</b></font>하는 역할을 하는 파일이다<br>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> model <span class="keyword">as</span> ml</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> DEFINES</span><br><span class="line"></span><br><span class="line"><span class="comment"># argc : 명령행에서 전달된 인자의 개수</span></span><br><span class="line"><span class="comment"># argv : 실제 들어오는 인자 &lt;font size=2&gt;(문자열 값)&lt;/font&gt;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">  arg_length = len(sys.argv)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(arg_length &lt; <span class="number">2</span>):</span><br><span class="line">      <span class="keyword">raise</span> Exception(<span class="string">"Don't call us. We'll call you"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 데이터를 통해 사전 구성</span></span><br><span class="line">  word2idx,  idx2char, vocabulary_length = data.load_vocabulary()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 테스트용 데이터 생성</span></span><br><span class="line">  print(sys.argv)</span><br><span class="line">  input = <span class="string">""</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">      input += i</span><br><span class="line">      input += <span class="string">" "</span></span><br><span class="line"></span><br><span class="line">  print(input)</span><br><span class="line">  predic_input_enc, predic_input_enc_length = data.enc_processing([input], word2idx)</span><br><span class="line">  <span class="comment"># 학습 과정이 아니므로 디코딩 입력은 존재하지 X</span></span><br><span class="line">  <span class="comment"># (구조 맞추기 위함)</span></span><br><span class="line">  predic_output_dec, predic_output_dec_length = data.dec_output_processing([<span class="string">""</span>], word2idx)</span><br><span class="line">  <span class="comment"># 학습 과정이 아니므로 디코딩 출력은 존재하지 X</span></span><br><span class="line">  <span class="comment"># (구조 맞추기 위함)</span></span><br><span class="line">  predic_target_dec = data.dec_target_processing([<span class="string">""</span>], word2idx)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Estimator 구성</span></span><br><span class="line">  classifier = tf.estimator.Estimator(</span><br><span class="line">          <span class="comment"># 모델 등록</span></span><br><span class="line">          model_fn=ml.Model,</span><br><span class="line">          <span class="comment"># 체크포인트 위치 등록</span></span><br><span class="line">          model_dir=DEFINES.check_point_path,</span><br><span class="line">          params=&#123; <span class="comment"># 모델 쪽으로 파라메터 전달한다.</span></span><br><span class="line">              <span class="comment"># 가중치 크기 설정</span></span><br><span class="line">              <span class="string">'hidden_size'</span>: DEFINES.hidden_size,</span><br><span class="line">              <span class="comment"># 학습률 설정</span></span><br><span class="line">              <span class="string">'learning_rate'</span>: DEFINES.learning_rate,</span><br><span class="line">              <span class="comment"># 딕셔너리 크기 설정</span></span><br><span class="line">              <span class="string">'vocabulary_length'</span>: vocabulary_length,</span><br><span class="line">               <span class="comment"># 임베딩 크기 설정</span></span><br><span class="line">              <span class="string">'embedding_size'</span>: DEFINES.embedding_size,</span><br><span class="line">              <span class="string">'max_sequence_length'</span>: DEFINES.max_sequence_length,</span><br><span class="line">          &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(DEFINES.max_sequence_length):</span><br><span class="line">      <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">          predic_output_dec, predic_output_decLength = data.dec_output_processing([answer], word2idx)</span><br><span class="line">          predic_target_dec = data.dec_target_processing([answer], word2idx)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 예측 수행</span></span><br><span class="line">      predictions = classifier.predict(input_fn=<span class="keyword">lambda</span>: data.eval_input_fn(predic_input_enc, predic_output_dec, predic_target_dec, <span class="number">1</span>))</span><br><span class="line">      answer = data.pred_next_string(predictions, idx2char)</span><br><span class="line">  <span class="comment"># 예측한 값을 텍스트로 변경</span></span><br><span class="line">  print(<span class="string">"answer: "</span>, answer)</span><br><span class="line"></span><br><span class="line">      </span><br></pre></td></tr></table></figure><br>    </div><br>  </div><br>  <div id="section8"><br>  <font size="5" color="purple"><b>정리 및 참고</b></font><br>  <hr color="purple"><br>  <div style=" text-align:center; vertical-align: middle; padding:30px 0;"><br>    구현한 모델은 단순히 한 방향의 재현 신경망 모델을 사용했기 때문에<br>    <b>문장이 길어질 수록 성능이 감소</b>할 수 있다<br>    <br><br>    <font size="4" color="blue"><b>[참고]</b></font><br>    <hr color="blue"><br>    <a href="https://github.com/changwookjun/Transformer" target="_blank" rel="noopener">https://github.com/changwookjun/Transformer</a><br>  </div><br></div></div></div></div></div></div></div></div></font>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://NAEJINHJ.github.com/2019/03/07/chatbot-modeling/" data-id="cjt5vw8za005x3sjj03hz8e0c" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="https://www.twitter.com" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="google-plus" href="https://www.google.co.kr" target="_blank" rel="noopener">
                        <i class="icon fa fa-google-plus"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/NAEJINHJ/naejinhj.github.io.git" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2019/03/09/botframework-chatbot/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            마카롱 주문 챗봇 with Bot Framework
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2019/03/03/chatbot_data_analy/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">딥러닝 모델을 통한 챗봇 만들기 : 데이터 분석</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/03/09/botframework-chatbot/" class="thumbnail">
    
    
        <span style="background-image:url(/image/NLP/botframework/macaroonbot.gif)" alt="마카롱 주문 챗봇 with Bot Framework" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Project/">Project</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Project/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2019/03/09/botframework-chatbot/" class="title">마카롱 주문 챗봇 with Bot Framework</a></p>
                            <p class="item-date"><time datetime="2019-03-09T06:57:25.514Z" itemprop="datePublished">2019-03-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/03/07/chatbot-modeling/" class="thumbnail">
    
    
        <span style="background-image:url(/image/NLP/chatbot/chatbot.PNG)" alt="딥러닝 모델을 통한 챗봇 만들기 : 모델링" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/BIGDATA/">BIGDATA</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/BIGDATA/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2019/03/07/chatbot-modeling/" class="title">딥러닝 모델을 통한 챗봇 만들기 : 모델링</a></p>
                            <p class="item-date"><time datetime="2019-03-07T02:58:59.337Z" itemprop="datePublished">2019-03-07</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/03/03/chatbot_data_analy/" class="thumbnail">
    
    
        <span style="background-image:url(/image/NLP/chatbot/chatbot.PNG)" alt="딥러닝 모델을 통한 챗봇 만들기 : 데이터 분석" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/BIGDATA/">BIGDATA</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/BIGDATA/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2019/03/03/chatbot_data_analy/" class="title">딥러닝 모델을 통한 챗봇 만들기 : 데이터 분석</a></p>
                            <p class="item-date"><time datetime="2019-03-02T16:09:29.346Z" itemprop="datePublished">2019-03-03</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/03/02/imdb-word2vec/" class="thumbnail">
    
    
        <span style="background-image:url(/image/NLP/kaggle_BOW.PNG)" alt="Bag of Words Meets Bags of Popcorn : word2vec" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Project/">Project</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Project/Kaggle/">Kaggle</a></p>
                            <p class="item-title"><a href="/2019/03/02/imdb-word2vec/" class="title">Bag of Words Meets Bags of Popcorn : word2vec</a></p>
                            <p class="item-date"><time datetime="2019-03-02T12:49:25.539Z" itemprop="datePublished">2019-03-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/02/24/kakao/" class="thumbnail">
    
    
        <span style="background-image:url(/image/NLP/kakao.gif)" alt="python으로 카카오톡 대화 분석하기" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/BIGDATA/">BIGDATA</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/BIGDATA/NLP/">NLP</a></p>
                            <p class="item-title"><a href="/2019/02/24/kakao/" class="title">python으로 카카오톡 대화 분석하기</a></p>
                            <p class="item-date"><time datetime="2019-02-24T14:38:26.109Z" itemprop="datePublished">2019-02-24</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BIGDATA/">BIGDATA</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/BIGDATA/DATA/">DATA</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/BIGDATA/Modeling/">Modeling</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/BIGDATA/Modeling/R/">R</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/BIGDATA/NLP/">NLP</a><span class="category-list-count">4</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Coding-Test/">Coding Test</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding-Test/Python/">Python</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DB/">DB</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DB/NoSQL/">NoSQL</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/LOG/">LOG</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/">Project</a><span class="category-list-count">9</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Project/BIGDATA/">BIGDATA</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/C/">C#</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/JAVA/">JAVA</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/Kaggle/">Kaggle</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Project/Kaggle/NLP/">NLP</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/NLP/">NLP</a><span class="category-list-count">1</span></li></ul></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/BIGDATA/">BIGDATA</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bot-Framework/">Bot_Framework</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C#</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chatbot/">Chatbot</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DB/">DB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA/">JAVA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaggle/">Kaggle</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LOG/">LOG</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/">MongoDB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NoSQL/">NoSQL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PLAN/">PLAN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Project/">Project</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/">R</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coding-test/">coding test</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data/">data</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/game/">game</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/log/">log</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/modeling/">modeling</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/">test</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/BIGDATA/" style="font-size: 20px;">BIGDATA</a> <a href="/tags/Bot-Framework/" style="font-size: 10px;">Bot_Framework</a> <a href="/tags/C/" style="font-size: 10px;">C#</a> <a href="/tags/Chatbot/" style="font-size: 13.33px;">Chatbot</a> <a href="/tags/DB/" style="font-size: 10px;">DB</a> <a href="/tags/JAVA/" style="font-size: 10px;">JAVA</a> <a href="/tags/Kaggle/" style="font-size: 13.33px;">Kaggle</a> <a href="/tags/LOG/" style="font-size: 10px;">LOG</a> <a href="/tags/MongoDB/" style="font-size: 10px;">MongoDB</a> <a href="/tags/NLP/" style="font-size: 16.67px;">NLP</a> <a href="/tags/NoSQL/" style="font-size: 10px;">NoSQL</a> <a href="/tags/PLAN/" style="font-size: 10px;">PLAN</a> <a href="/tags/Project/" style="font-size: 15px;">Project</a> <a href="/tags/R/" style="font-size: 15px;">R</a> <a href="/tags/coding-test/" style="font-size: 10px;">coding test</a> <a href="/tags/data/" style="font-size: 10px;">data</a> <a href="/tags/game/" style="font-size: 11.67px;">game</a> <a href="/tags/log/" style="font-size: 10px;">log</a> <a href="/tags/modeling/" style="font-size: 16.67px;">modeling</a> <a href="/tags/python/" style="font-size: 18.33px;">python</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                  <a href="/" style="font-size:20px;color:#fff; text-decoration: none;">NA'rchive</a>
                </h1>
                <p>&copy; 2019 Hyejin</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'https://NAEJINHJ.github.com/2019/03/07/chatbot-modeling/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
